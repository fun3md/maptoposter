{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15480a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Execution ---\n",
    "input_img_path = 'output_dither.png' # The \"clean\" image\n",
    "#input_img_path = '../posters/magdeburg_gradient_roads_20260121_101401.png' # The \"clean\" image\n",
    "power_levels = np.array([0.0, 0.6, 0.8, 1.0], dtype=np.float32)\n",
    "target_image_dpi = 400 # Set this to the DPI of your input_img_path\n",
    "TARGET_LONGEST_EDGE_MM = 170  # Set the desired length of the longest side in mm\n",
    "runout_mm = 2.0\n",
    "\n",
    "pre_adj_strength = 1.5\n",
    "pre_gamma = 2.2\n",
    "lut_file = 'uv_laser_correction_inverted.csv'\n",
    "\n",
    "\n",
    "BLUE_NOISE_PATH = os.path.join('..', 'bluenoise', '128_128', 'LDR_LLL1_0.png')\n",
    "kernel_file = 'averaged_deconvolution_kernel.npy'\n",
    "kernel_source_dpi = 1200\n",
    "\n",
    "# --- Dither ---\n",
    "# Adjust these paths as needed\n",
    "INPUT_IMAGE_PATH = \"corrected_pre_dither.png\"\n",
    "post_img_path = 'post_dither.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_dot_gain(image_path, kernel_path, source_dpi=1200, target_dpi=300):\n",
    "    # 1. Load the target image and the kernel\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(\"Target image not found.\")\n",
    "    \n",
    "    scale_factor_in = source_dpi / target_dpi\n",
    "    img_newx =  int(round(img.shape[1] * scale_factor_in))\n",
    "    img_newy =  int(round(img.shape[0] * scale_factor_in))\n",
    "\n",
    "    img_scaled = cv2.resize(img, (img_newx, img_newy), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Load the 1200dpi kernel we saved earlier\n",
    "    kernel_1200 = np.load(kernel_path)\n",
    "    \n",
    "    # # 2. Scale the kernel to match the target image DPI\n",
    "    # # If target is 300dpi and source is 1200dpi, scale is 0.25\n",
    "    # scale_factor = target_dpi / source_dpi\n",
    "    # new_size = int(round(kernel_1200.shape[0] * scale_factor))\n",
    "    \n",
    "    # # Ensure size is odd for a centered kernel\n",
    "    # if new_size % 2 == 0:\n",
    "    #     new_size += 1\n",
    "        \n",
    "    # # Resize the kernel using inter-area interpolation (best for shrinking)\n",
    "    # kernel_scaled = cv2.resize(kernel_1200, (new_size, new_size), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # # IMPORTANT: Re-normalize after resizing so the sum remains 1.0\n",
    "    # # This ensures the image doesn't get brighter or darker\n",
    "    # kernel_scaled /= kernel_scaled.sum()\n",
    "    \n",
    "    # 3. Apply the simulation\n",
    "    # To simulate ink spreading (dot gain), we convolve the image.\n",
    "    # filter2D handles multi-channel images (BGR) automatically.\n",
    "    simulated_img = cv2.filter2D(img_scaled, -1, kernel_1200)\n",
    "\n",
    "    simulated_img = cv2.resize(simulated_img,(int(round(img.shape[1])), int(round(img.shape[0]))), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "    # 4. Optional: Non-linear Dot Gain Adjustment\n",
    "    # Physical dot gain is often non-linear (darker areas spread more).\n",
    "    # You can simulate this by slightly darkening the midtones (gamma correction)\n",
    "    # gamma = 1.1 \n",
    "    # simulated_img = np.array(255 * (simulated_img / 255) ** gamma, dtype='uint8')\n",
    "\n",
    "    return img, simulated_img, kernel_1200\n",
    "\n",
    "# original, simulated, final_kernel = apply_dot_gain(\n",
    "#     input_img_path, \n",
    "#     kernel_file, \n",
    "#     source_dpi=1200, \n",
    "#     target_dpi=target_image_dpi\n",
    "# )\n",
    "\n",
    "# --- Visualization ---\n",
    "# plt.figure(figsize=(15, 7))\n",
    "\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.title(f\"Original Digital Image ({target_image_dpi} DPI)\")\n",
    "# plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.title(\"Simulated Printed Dot Gain\")\n",
    "# plt.imshow(cv2.cvtColor(simulated, cv2.COLOR_BGR2RGB))\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.title(f\"Rescaled Kernel ({final_kernel.shape[0]}px)\")\n",
    "# plt.imshow(final_kernel, cmap='viridis')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Save the result\n",
    "#cv2.imwrite('simulated_print_output.png', simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98730376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_cyanotype_correction(image_path, kernel_path, lut_csv_path, target_gamma=2.2, strength=1.0):\n",
    "    # 1. Load Image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None: raise FileNotFoundError(\"Image not found\")\n",
    "    img = img.astype(np.float32) / 255.0  # Work in 0.0-1.0 range for gamma\n",
    "\n",
    "    # 2. Step 1: Gamma Pre-Compensation\n",
    "    # If paper darkens with gamma 2.2, we lighten with 1/2.2\n",
    "    gamma_corrected = np.power(img, 1.0 / target_gamma)\n",
    "\n",
    "    # 3. Step 2: LUT Compensation (from your CSV)\n",
    "    # We load the CSV and find the inverse mapping\n",
    "    df = pd.read_csv(lut_csv_path).sort_values(by='Input')\n",
    "    \n",
    "    # Check if CSV is Density (0=White) or Brightness (255=White)\n",
    "    # If the end of the curve is lower than the start, it's Density. Flip it.\n",
    "    if df['Output'].iloc[-1] < df['Output'].iloc[0]:\n",
    "        df['Output'] = 255 - df['Output']\n",
    "\n",
    "    # Create the inverse LUT: \"What digital value gives this paper output?\"\n",
    "    all_vals = np.linspace(0, 1, 256)\n",
    "    # Interpolate using normalized 0-1 values\n",
    "    xp = df['Output'].values / 255.0\n",
    "    fp = df['Input'].values / 255.0\n",
    "    \n",
    "    # Generate the compensation curve\n",
    "    inv_lut_vals = np.interp(all_vals, xp, fp)\n",
    "    \n",
    "    # Apply LUT to the gamma-corrected image\n",
    "    # We use a simple interpolation to apply the curve to the float image\n",
    "    final_toned = np.interp(gamma_corrected, all_vals, inv_lut_vals)\n",
    "\n",
    "    # 4. Step 3: Spatial Deconvolution (Sharpening)\n",
    "    # Use your 1200dpi kernel to counteract physical bleeding\n",
    "    kernel_1200 = np.load(kernel_path)\n",
    "\n",
    "    scale_factor = 1200 / target_image_dpi\n",
    "    new_size = int(round(kernel_1200.shape[0] * scale_factor))\n",
    "    if new_size % 2 == 0: new_size += 1\n",
    "    \n",
    "    kernel_small = cv2.resize(kernel_1200, (new_size, new_size), interpolation=cv2.INTER_AREA)\n",
    "    kernel_small /= kernel_small.sum()\n",
    "\n",
    "    # High-pass sharpening logic\n",
    "    blurred = cv2.filter2D(final_toned, -1, kernel_small)\n",
    "    sharpened = final_toned + (final_toned - blurred) * strength\n",
    "    \n",
    "    # 5. Final Output\n",
    "    final_img = np.clip(sharpened * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # --- Visualization ---\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(cv2.cvtColor((img*255).astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Combined Correction Curve\")\n",
    "    plt.plot(all_vals, inv_lut_vals, label=\"Inverted LUT\")\n",
    "    plt.plot(all_vals, np.power(all_vals, 1/target_gamma), label=f\"Gamma 1/{target_gamma}\", alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Pre-Compensated (Print this)\")\n",
    "    plt.imshow(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    return final_img\n",
    "\n",
    "# --- EXECUTION ---\n",
    "corrected = apply_cyanotype_correction(\n",
    "    image_path=input_img_path,\n",
    "    kernel_path=kernel_file,\n",
    "    lut_csv_path=lut_file,\n",
    "    target_gamma=pre_gamma, # Standard cyanotype contrast\n",
    "    strength=pre_adj_strength      # Adjust sharpening strength (0.0 to 1.5)\n",
    ")\n",
    "\n",
    "cv2.imwrite('corrected_pre_dither.png', corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f534bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 2. Helper Functions\n",
    "# ==========================================\n",
    "\n",
    "def load_and_normalize(path):\n",
    "    \"\"\"Loads an image, converts to float, normalizes to 0-1.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    \n",
    "    img = Image.open(path)\n",
    "    img = img.convert('RGB') # Ensure RGB\n",
    "    return np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "def rgb_to_grayscale_perceptual(img_rgb):\n",
    "    \"\"\"\n",
    "    Converts RGB to Grayscale using Rec. 601 Luma coefficients.\n",
    "    L = 0.299*R + 0.587*G + 0.114*B\n",
    "    \"\"\"\n",
    "    # img_rgb shape is (H, W, 3)\n",
    "    r = img_rgb[:, :, 0]\n",
    "    g = img_rgb[:, :, 1]\n",
    "    b = img_rgb[:, :, 2]\n",
    "    \n",
    "    gray = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return gray\n",
    "\n",
    "def tile_noise(noise_texture, target_shape):\n",
    "    \"\"\"\n",
    "    Tiles the noise texture to cover the target image shape.\n",
    "    target_shape: (Height, Width)\n",
    "    \"\"\"\n",
    "    th, tw = target_shape\n",
    "    nh, nw = noise_texture.shape\n",
    "    \n",
    "    # Calculate how many times to repeat in Y and X\n",
    "    repeat_y = (th // nh) + 1\n",
    "    repeat_x = (tw // nw) + 1\n",
    "    \n",
    "    # Tile and crop to exact size\n",
    "    tiled = np.tile(noise_texture, (repeat_y, repeat_x))\n",
    "    return tiled[:th, :tw]\n",
    "\n",
    "def resize_to_physical_dim(pil_img, longest_edge_mm, dpi):\n",
    "    target_pixels_max = int((longest_edge_mm / 25.4) * dpi)\n",
    "    \n",
    "    # FIX: Handle both PIL Images and NumPy Arrays\n",
    "    if hasattr(pil_img, 'shape'):  # It's a NumPy array\n",
    "        h, w = pil_img.shape[:2]   # shape is (Height, Width, Channels)\n",
    "        is_numpy = True\n",
    "    else:                          # It's a PIL Image\n",
    "        w, h = pil_img.size        # size is (Width, Height)\n",
    "        is_numpy = False\n",
    "        \n",
    "    # Calculate scale maintaining aspect ratio\n",
    "    if w > h:\n",
    "        scale = target_pixels_max / w\n",
    "    else:\n",
    "        scale = target_pixels_max / h\n",
    "        \n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "\n",
    "    # Perform resize\n",
    "    if is_numpy:\n",
    "        import cv2\n",
    "        # OpenCV uses (width, height) for resize, but input was array\n",
    "        return cv2.resize(pil_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        return pil_img.resize((new_w, new_h), resample=Image.LANCZOS)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. Main Logic\n",
    "# ==========================================\n",
    "\n",
    "try:\n",
    "    # A. Load Input Image\n",
    "    print(f\"Loading image: {INPUT_IMAGE_PATH}\")\n",
    "    img_rgb = load_and_normalize(INPUT_IMAGE_PATH)\n",
    "    img_rgb = resize_to_physical_dim(img_rgb, TARGET_LONGEST_EDGE_MM, target_image_dpi)\n",
    "    # B. Convert to Grayscale Perceptually\n",
    "    img_gray = rgb_to_grayscale_perceptual(img_rgb)\n",
    "    print(f\"Image Size: {img_gray.shape}\")\n",
    "\n",
    "    # C. Load Blue Noise Texture\n",
    "    print(f\"Loading noise: {BLUE_NOISE_PATH}\")\n",
    "    # Load noise, convert to grayscale (L), normalize 0-1\n",
    "    noise_img = Image.open(BLUE_NOISE_PATH).convert('L')\n",
    "    noise_arr = np.array(noise_img).astype(np.float32) / 255.0\n",
    "\n",
    "    # D. Tile the Noise to match Image Size\n",
    "    noise_tiled = tile_noise(noise_arr, img_gray.shape)\n",
    "\n",
    "    #power_levels = np.array([0.0, 0.0, 0.8, 1.0], dtype=np.float32)\n",
    "\n",
    "    # 2. Convert Image Brightness to Target Laser Power\n",
    "    # Assuming img_gray: 1.0 = White (Paper), 0.0 = Black (Ink)\n",
    "    # We invert this because for the laser: 0.0 = Off (Paper), 1.0 = On (Burn)\n",
    "    target_power = img_gray\n",
    "\n",
    "    # Ensure range is strictly 0-1\n",
    "    target_power = np.clip(target_power, 0.0, 1.0)\n",
    "\n",
    "    # 3. Find the Lower and Upper bounds for every pixel\n",
    "    # We find which interval of power_levels the current pixel falls into.\n",
    "    # np.searchsorted finds the insertion index to maintain order.\n",
    "    # We subtract 1 to get the index of the \"step below\".\n",
    "    idx = np.searchsorted(power_levels, target_power, side='right') - 1\n",
    "\n",
    "    # Clamp indices to ensure we don't go out of bounds\n",
    "    idx = np.clip(idx, 0, len(power_levels) - 2)\n",
    "\n",
    "    lower_step = power_levels[idx]\n",
    "    upper_step = power_levels[idx + 1]\n",
    "\n",
    "    # 4. Normalize the pixel value within its specific step interval\n",
    "    # Example: If pixel wants 0.7 power, it sits between 0.5 and 0.9.\n",
    "    # The normalized value (0.0 to 1.0) represents how close it is to the upper step.\n",
    "    step_range = upper_step - lower_step\n",
    "\n",
    "    # Handle case where step_range is 0 to avoid division by zero\n",
    "    step_range[step_range == 0] = 1.0 \n",
    "\n",
    "    normalized_val = (target_power - lower_step) / step_range\n",
    "\n",
    "    # 5. Apply the Blue Noise Threshold\n",
    "    # If the normalized value is higher than the noise, bump up to the upper step.\n",
    "    # Otherwise, stay at the lower step.\n",
    "    step_up_mask = normalized_val > noise_tiled\n",
    "\n",
    "    dithered_output = np.where(step_up_mask, upper_step, lower_step)\n",
    "\n",
    "    runout_px = int((runout_mm / 25.4) * target_image_dpi)\n",
    "\n",
    "    # FIX: Convert NumPy array to PIL Image\n",
    "    # Ensure the array is uint8 (0-255) or bool before converting\n",
    "    if isinstance(dithered_output, np.ndarray):\n",
    "        # If your dithered output is float (0.0-1.0), scale to 255\n",
    "        if dithered_output.max() <= 1.0:\n",
    "            dithered_output = (dithered_output * 255).astype(np.uint8)\n",
    "        \n",
    "        dithered_output = Image.fromarray(dithered_output.astype(np.uint8))\n",
    "\n",
    "    # Now this will work\n",
    "    dithered_output = ImageOps.expand(dithered_output, border=runout_px, fill='white')\n",
    "\n",
    "    # Output is now an array containing only [0.0, 0.5, 0.9, 1.0]\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. Visualization\n",
    "    # ==========================================\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Original Grayscale\n",
    "    ax[0].imshow(img_gray, cmap='gray', vmin=0, vmax=1)\n",
    "    ax[0].set_title(\"Perceptual Grayscale Input\")\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # Dithered Result\n",
    "    ax[1].imshow(dithered_output, cmap='gray', vmin=0, vmax=1)\n",
    "    ax[1].set_title(\"Blue Noise Dithered\")\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    # The Noise Mask (Zoomed in snippet for visualization)\n",
    "    ax[2].imshow(noise_tiled, cmap='gray', vmin=0, vmax=1)\n",
    "    ax[2].set_title(\"Tiled Blue Noise Map\")\n",
    "    ax[2].axis('off')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: Save result\n",
    "    dithered_output.save('post_dither.png')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Ensure 'xyz.png' exists and the blue noise path is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2617ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_paper_texture(shape, scale=0.5, intensity=0.05):\n",
    "    \"\"\"Procedurally generates a watercolor paper texture (Aquarell).\"\"\"\n",
    "    # Create random noise\n",
    "    noise = np.random.normal(128, 20, (shape[0], shape[1])).astype(np.uint8)\n",
    "    # Blur it to create \"clumps\" like paper pulp\n",
    "    pulp = cv2.GaussianBlur(noise, (5, 5), 0)\n",
    "    pulp = cv2.resize(pulp, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    pulp = pulp[:shape[0], :shape[1]]\n",
    "    \n",
    "    # Use Sobel to create a \"bump map\" effect (lighting from top-left)\n",
    "    kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "    edge_x = cv2.filter2D(pulp, -1, kernel_x)\n",
    "    edge_y = cv2.filter2D(pulp, -1, kernel_y)\n",
    "    \n",
    "    texture = (edge_x + edge_y).astype(np.float32) * intensity\n",
    "    return texture\n",
    "\n",
    "def apply_print_simulation(image_path, kernel_path, lut_csv_path, source_dpi=1200, target_dpi=300):\n",
    "    # 1. Load the target image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(\"Target image not found.\")\n",
    "    \n",
    "     # Paper: White-ish\n",
    "    PAPER_COLOR = np.array([192, 200, 202]) # BGR (flipped from your original)\n",
    "    # Indigo: Dark Blue\n",
    "    INDIGO_PIGMENT = np.array([105, 65, 45]) # BGR (flipped from your original)\n",
    "    \n",
    "    scale_factor_in = source_dpi / target_dpi\n",
    "    img_newx =  int(round(img.shape[1] * scale_factor_in))\n",
    "    img_newy =  int(round(img.shape[0] * scale_factor_in))\n",
    "\n",
    "    img = cv2.resize(img, (img_newx, img_newy), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # 2. Load and Invert the LUT\n",
    "    df_lut = pd.read_csv(lut_csv_path)\n",
    "    df_lut = df_lut.sort_values(by='Input')\n",
    "    \n",
    "    all_inputs = np.arange(256)\n",
    "    # Original interpolation\n",
    "    lut_values = np.interp(all_inputs, df_lut['Input'], df_lut['Output'])\n",
    "    \n",
    "    # --- INVERSION LOGIC ---\n",
    "    # This flips the response. If the LUT was \"Darker\", it now becomes \"Lighter\"\n",
    "    # Formula: New_Output = 255 - Old_Output\n",
    "    lut_values = 255 - lut_values\n",
    "    \n",
    "    # Ensure values stay in 0-255 range and convert to uint8\n",
    "    lut_values = np.clip(lut_values, 0, 255).astype(np.uint8)\n",
    "    opencv_lut = lut_values.reshape((1, 256))\n",
    "\n",
    "    # 3. Load and Scale the Kernel\n",
    "    kernel_1200 = np.load(kernel_path)\n",
    "    # scale_factor = target_dpi / source_dpi\n",
    "    # new_size = int(round(kernel_1200.shape[0] * scale_factor))\n",
    "    # if new_size % 2 == 0: new_size += 1\n",
    "    \n",
    "    # kernel_scaled = cv2.resize(kernel_1200, (new_size, new_size), interpolation=cv2.INTER_AREA)\n",
    "    # kernel_scaled /= kernel_scaled.sum()\n",
    "\n",
    "    # 4. Apply the Simulation\n",
    "    # Apply Inverted Tone Response\n",
    "    \n",
    "    \n",
    "    # Apply Spatial Dot Gain\n",
    "    simulated_img = cv2.filter2D(img, -1, kernel_1200)\n",
    "    \n",
    "\n",
    "    simulated_img = cv2.resize(simulated_img,(int(round(img.shape[1])), int(round(img.shape[0]))), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    h, w = simulated_img.shape[:2]\n",
    "    simulated_rgb = np.zeros((h, w, 3), dtype=np.float32)\n",
    "\n",
    "    # Normalize image to 0.0 - 1.0 range\n",
    "    # Assuming the input image uses 255 for White (Paper) and 0 for Black (Ink)\n",
    "    norm_img = simulated_img.astype(np.float32) / 255.0\n",
    "\n",
    "    # Calculate Ink Density\n",
    "    # If pixel is 255 (White), density is 0.0. If pixel is 0 (Black), density is 1.0.\n",
    "    ink_density = 1.0 - norm_img\n",
    "    \n",
    "    # Optional: Apply Gamma/Curve to ink density to simulate absorption\n",
    "    ink_density = np.power(ink_density, 0.8) \n",
    "\n",
    "    # --- FIX 2: CORRECT BLENDING MATH ---\n",
    "    for i in range(3): # For B, G, R\n",
    "        # Linear Interpolation: \n",
    "        # When density is 0 (Paper), we keep 100% Paper.\n",
    "        # When density is 1 (Ink), we keep 100% Ink.\n",
    "        \n",
    "        # Method A: Standard Linear Interpolation (Opaque ink)\n",
    "        #simulated_rgb[:,:,i] = (PAPER_COLOR[i] * (1.0 - ink_density)) + (INDIGO_PIGMENT[i] * ink_density)\n",
    "\n",
    "        # Method B: Subtractive Mixing (More realistic for translucent watercolor/ink)\n",
    "        # Uses Multiply blend mode logic. \n",
    "        # Uncomment below to try:\n",
    "        paper_channel = PAPER_COLOR[i]\n",
    "        ink_channel = INDIGO_PIGMENT[i]\n",
    "        # As density goes up, we transition from Paper to (Paper * Ink_Normalized)\n",
    "        simulated_rgb[:,:,i] = paper_channel * (1.0 - ink_density) + (paper_channel * (ink_channel/255.0)) * ink_density\n",
    "\n",
    "    # 5. Add Paper Texture\n",
    "    # Ensure generated texture matches image size\n",
    "    # (Assuming generate_paper_texture returns a value to add, e.g., -10 to +10)\n",
    "    # Note: Ensure generate_paper_texture is defined elsewhere in your code\n",
    "    try:\n",
    "        texture = generate_paper_texture((h, w), intensity=0.08)\n",
    "        \n",
    "        # If texture is single channel, broadcast it\n",
    "        if len(texture.shape) == 2:\n",
    "            texture = np.expand_dims(texture, axis=2)\n",
    "            \n",
    "        simulated_rgb += texture\n",
    "    except NameError:\n",
    "        print(\"Warning: generate_paper_texture function not found, skipping texture.\")\n",
    "\n",
    "    return img, np.clip(simulated_rgb, 0, 255).astype(np.uint8), lut_values\n",
    "\n",
    "def apply_print_simulation_alt(image_path, kernel_path, lut_csv_path, source_dpi=1200, target_dpi=300):\n",
    "     # 1. Load Image\n",
    "    img_in = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_in is None: raise FileNotFoundError(\"Input image not found.\")\n",
    "\n",
    "    scale_factor_in = source_dpi / target_dpi\n",
    "    img_newx =  int(round(img_in.shape[1] * scale_factor_in))\n",
    "    img_newy =  int(round(img_in.shape[0] * scale_factor_in))\n",
    "    img = cv2.resize(img_in, (img_newx, img_newy), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # 2. Fix the Inverted LUT Logic\n",
    "    df_lut = pd.read_csv(lut_csv_path).sort_values(by='Input')\n",
    "    all_inputs = np.arange(256)\n",
    "    \n",
    "    # We create the LUT from your CSV\n",
    "    lut_raw = np.interp(all_inputs, df_lut['Input'], df_lut['Output'])\n",
    "    \n",
    "    # LOGIC CHECK: \n",
    "    # If the user sends a white pixel (255), we want 0 density.\n",
    "    # If the user sends a black pixel (0), we want max density.\n",
    "    # We force the LUT to be a \"Digital-to-Ink\" map where 255 digital = 0 ink.\n",
    "    if lut_raw[255] > lut_raw[0]:\n",
    "        # If 255 digital resulted in high output, we must flip it\n",
    "        lut_map = 255 - lut_raw\n",
    "    else:\n",
    "        lut_map = lut_raw\n",
    "\n",
    "    # Apply the mapping to get Ink Density (0.0 to 1.0)\n",
    "    ink_density = cv2.LUT(img, lut_map.astype(np.uint8).reshape((1, 256))).astype(np.float32) / 255.0\n",
    "\n",
    "    # 3. Handle Kernel (Spatial Spread)\n",
    "    kernel_1200 = np.load(kernel_path).astype(np.float32)\n",
    "    kernel_1200 /= (kernel_1200.sum() + 1e-8)\n",
    "    \n",
    "    # scale = target_dpi / source_dpi\n",
    "    # k_size = int(round(kernel_1200.shape[0] * scale))\n",
    "    # if k_size % 2 == 0: k_size += 1\n",
    "    # kernel_scaled = cv2.resize(kernel_1200, (k_size, k_size), interpolation=cv2.INTER_AREA)\n",
    "    # kernel_scaled /= (kernel_scaled.sum() + 1e-8)\n",
    "\n",
    "    # Spread the ink\n",
    "    spread_density = cv2.filter2D(ink_density, -1, kernel_1200)\n",
    "\n",
    "    # 4. Subtractive Overlap (Capping)\n",
    "    k_val = 2.5 \n",
    "    saturated_density = 1.0 - np.exp(-k_val * spread_density)\n",
    "    saturated_density = np.clip(saturated_density, 0, 1)\n",
    "\n",
    "    # 5. Final RGB Color Mapping\n",
    "    PAPER_WHITE = np.array([222, 230, 232]) # BGR (flipped from your original)\n",
    "    # Indigo: Dark Blue\n",
    "    INDIGO_DARK = np.array([65, 25, 5]) # BGR (flipped from your original)\n",
    "    \n",
    "    h, w = saturated_density.shape\n",
    "    sim_rgb = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    \n",
    "    for i in range(3):\n",
    "        # 0.0 Density = Paper Color\n",
    "        # 1.0 Density = Indigo Color\n",
    "        sim_rgb[:,:,i] = (1.0 - saturated_density) * PAPER_WHITE[i] + (saturated_density) * INDIGO_DARK[i]\n",
    "\n",
    "    # 6. Add Texture\n",
    "    grain = np.random.normal(0, 1.2, (h, w))\n",
    "    for i in range(3): sim_rgb[:,:,i] += grain\n",
    "\n",
    "    # Debug: Confirm inversion is correct\n",
    "    # Corner pixels in digital images are usually background (White/255)\n",
    "    # They should have near-zero density.\n",
    "    print(f\"Top-Left Pixel Digital Value: {img[0,0]}\")\n",
    "    print(f\"Top-Left Pixel Ink Density: {ink_density[0,0]:.4f}\")\n",
    "\n",
    "    sim_rgb = cv2.resize(sim_rgb,(int(round(img.shape[1])), int(round(img.shape[0]))), interpolation=cv2.INTER_AREA)\n",
    "    return img,np.clip(sim_rgb, 0, 255).astype(np.uint8), lut_map\n",
    "\n",
    "\n",
    "original, simulated, inverted_lut = apply_print_simulation_alt(\n",
    "    post_img_path, \n",
    "    kernel_file, \n",
    "    lut_file,\n",
    "    source_dpi=kernel_source_dpi,\n",
    "    target_dpi=target_image_dpi # Adjust to your digital image resolution\n",
    ")\n",
    "\n",
    "#simulated = cv2.LUT(simulated, inverted_lut)    \n",
    "simulated = simulated.astype(np.float32) / 255.0\n",
    "#simulated = np.power(simulated, 1.4)\n",
    "simulated = np.clip(simulated * 255.0, 0, 230).astype(np.uint8)\n",
    "cv2.imwrite('simulated_paper_conv.png', simulated)\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Simulated (Inverted LUT)\")\n",
    "plt.imshow(cv2.cvtColor(simulated, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Inverted LUT Curve\")\n",
    "plt.plot(inverted_lut, color='red', label='Inverted Response')\n",
    "plt.plot([0, 255], [255, 0], 'k--', alpha=0.3, label='Full Negative')\n",
    "plt.xlabel('Digital Input')\n",
    "plt.ylabel('Simulated Output')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
